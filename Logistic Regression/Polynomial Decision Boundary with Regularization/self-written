import numpy as np
import matplotlib.pyplot as plt

#########################################################################
##### Gradient descent for logistic regression with regularization ###
#########################################################################
##### separate data as input and output
data = np.loadtxt("ex2data2.txt", delimiter=',')
X = data[:, 0:-1]
y = data[:, -1].reshape(-1, 1)
pos_idx = np.where(y==1)[0]
neg_idx = np.where(y==0)[0]
X_pos = X[pos_idx]
X_neg = X[neg_idx]
plot1 = plt.figure(1)
plt.plot(X_pos[:, 0], X_pos[:, 1], "+k", label="y=1")
plt.plot(X_neg[:, 0], X_neg[:, 1], "oy", label="y=0")
plt.xlabel("Exam 1 score")
plt.ylabel("Exam 2 score")
plt.title("Scatter plot of training data")
plt.legend(loc="upper right")


##### Since the decision boundary seems a circle, we use polynomial of X
##### Then, we use regularization to shrink variables, i.e., lambda = 1

##### Standardize data
miu = X.mean(axis=0).reshape(1, -1)
sigma = X.std(axis=0).reshape(1, -1)
for i in range(X.shape[1]):
    X[:, i] = ( X[:, i] - miu[:, i] ) / sigma[:, i]



##### Transform data to polynomial form:
def PolynomialTransformation(X, degree):
    X1 = X[:, 0].reshape(-1, 1)
    X2 = X[:, 1].reshape(-1, 1)
    result = np.ones(X.shape[0]).reshape(-1, 1)
    for i in range(1, degree+1):
        for j in range(i+1):
            result = np.c_[result, (X1**(i-j))*(X2**j)]
    return result

##### we choose degree = 6 here
degree = 6
X = PolynomialTransformation(X, degree)


def sigmoid(Z):
    result = np.zeros((Z.shape[0], Z.shape[1]))
    for i in range(Z.shape[0]):
        for j in range(Z.shape[1]):
            result[i, j] = 1/(1+np.exp(-Z[i, j]))
    return result

def loss_function(X, y, theta, lamb):
    m = X.shape[0]
    theta_no_intercept = theta[1:, 0].reshape(-1, 1)
    J = ( y.T @ np.log(sigmoid(X@theta)) +  (1-y).T @ np.log(1- sigmoid(X@theta)) )/ (- m)  + theta_no_intercept.T @ theta_no_intercept * (lamb/(2*m))
    grad = X.T @ (sigmoid(X@theta) - y) / m  + np.r_[np.array([[0]]), (lamb/m)*theta_no_intercept]

    return [J, grad]

def LogisticRegressionGradientDescent(X, y, lamb, alpha, tol, iter_max):
    iter = 0
    theta = np.zeros(X.shape[1]).reshape(-1, 1)
    J_history = loss_function(X, y, theta, lamb)[0]
    while True:
        J_best = J_history.min()

        # gradient descent iteration, see Andrew's class for details
        grad = loss_function(X, y, theta, lamb)[1]
        theta = theta - alpha * grad

        J = loss_function(X, y, theta, lamb)[0]
        J_history = np.append(J_history, J)
        iter += 1

        if np.absolute(J_best - J) < tol or iter == iter_max:
            break

    return [theta, J_history, iter]

##### we choose lambda = 1 here
lamb = 1 #strength regularization
alpha = 0.01 #step size
tol = 10**-4
iter_max = 10000
[theta, J_history, iter] = LogisticRegressionGradientDescent(X, y, lamb, alpha, tol, iter_max)
print("Coefficients (including intercept): \n", theta)
print("Loss in epochs: \n", J_history)
print("Total iterations to stop: \n", iter)

##### track loss (J) in iterations
plot2 = plt.figure(2)
plt.plot(J_history)
plt.xlabel("Epochs")
plt.ylabel("Loss (J)")
plt.title("Loss (J) in Epochs")

#########################################################################
##### Plot decision boundary (with standardized data) ###################
#########################################################################
pos_idx = np.where(y==1)[0]
neg_idx = np.where(y==0)[0]
X_pos = X[pos_idx]
X_neg = X[neg_idx]
plot3 = plt.figure(3)
##### remember we've added column of 1 to X, so we plot the second/third column of X
plt.plot(X_pos[:, 1], X_pos[:, 2], "+k", label="y=1")
plt.plot(X_neg[:, 1], X_neg[:, 2], "oy", label="y=0")

##### a function to define contour function with polynomial
def cnt(x, y, coef):
    idx = 0
    result = coef[idx, 0]
    for i in range(1, degree + 1):
        for j in range(i + 1):
            idx += 1
            result += (x ** (i - j)) * (y ** j) * coef[idx, 0]
    return result



##### set the x-axies a little bit beyond extremes (+-0.2)
exam1 = np.arange(X[:, 1].min()-0.2,X[:, 1].max()+0.2,0.1)
exam2 = np.arange(X[:, 2].min()-0.2,X[:, 2].max()+0.2,0.1)
coord1, coord2 = np.meshgrid(exam1,exam2)
plt.contour(exam1, exam2, cnt(coord1, coord2, theta), [0])


##### plt.axis([a, b, c, d]) set x_lim to (a, b), y_lim to (c, d)
plt.axis( [X[:, 1].min()-0.2, X[:, 1].max()+0.2, X[:, 2].min()-0.2, X[:, 2].max()+0.2] )
plt.xlabel("Exam 1 score")
plt.ylabel("Exam 2 score")
plt.title("Decision boundary of standardized training data")
plt.legend(loc="upper right")

##### predict for values
def predict(X, theta):
    pred = np.zeros((X.shape[0], 1))
    prob = sigmoid(X@theta)
    for i in range(X.shape[0]):
        if prob[i, 0] >= 0.5:
            pred[i, 0] = 1
        else:
            pred[i, 0] = 0
    return pred


##### check accuracy
def accuracy(X, y, theta):
    pred = predict(X, theta)
    return 1 - (pred - y).T @ (pred - y) / X.shape[0]

##### calculate accuracy
print("Accuracy in full set: \n", accuracy(X, y, theta))

#########################################################################
##### Prediction ########################################################
#########################################################################
##### predict for a new input X, say exam1 = 1, exam2 = 1
test = np.array([[1, 1]])
##### normalize it
for i in range(test.shape[1]):
    test[:, i] = ( test[:, i] - miu[:, i] ) / sigma[:, i]
##### add intercept
test = PolynomialTransformation(test, degree)
##### prediction
print("Prediction for new X=(1, 1): \n", predict(test, theta))

#########################################################################
##### k-fold cross validation ###########################################
#########################################################################

def GenerateLables(X, k):
    labels = []
    for i in range(k):
        labels.extend([i] * (X.shape[0] // k))
    if X.shape[0] // k != 0:
        for j in range(X.shape[0] % k):
            labels.extend([j])
            labels.sort()
    labels_array = np.array(labels).reshape(-1, 1)
    return labels_array

##### Note!!! To avoid data leakage, we can't standardize the entire dataset before separating to train/test
##### We have to standardize the train data first, then use the mean/sd from train to scale test.
##### So we need to use original data and Pipeline

##### Obtain original data again
data = np.loadtxt("ex2data1.txt", delimiter=',')
X = data[:, 0:-1]
y = data[:, -1]

def KFoldCrossValidation(X, y, k):
    ##### combine X and y if they are separated already
    X_y = np.c_[X, y]
    ##### always shuffle the data before CV
    np.random.shuffle(X_y)
    ##### generate (vertical vector) labels
    labels = GenerateLables(X_y, k)
    ##### attach labels to data
    X_y_shuffled_labeled = np.c_[labels, X_y]
    ##### create a matrix to store accuracy (row: fold1, ... foldk. column: train MSE, test MSE)
    acc = np.zeros((k, 2))
    for i in range(k):
        ##### select data with label = i as test set
        test = X_y_shuffled_labeled[X_y_shuffled_labeled[:, 0] == i, :]
        ##### select data with label = i as train set
        train = X_y_shuffled_labeled[X_y_shuffled_labeled[:, 0] != i, :]
        X_test = test[:, 1:-1]
        y_test = test[:, -1].reshape(-1, 1)
        X_train = train[:, 1:-1]
        y_train = train[:, -1].reshape(-1, 1)

        ##### Standardize train set
        miu_train = X_train.mean(axis=0).reshape(1, -1)
        sigma_train = X_train.std(axis=0).reshape(1, -1)
        for j in range(X_train.shape[1]):
            X_train[:, j] = (X_train[:, j] - miu_train[:, j]) / sigma_train[:, j]
        ##### make polynomial (and the first column of 1)
        X_train = PolynomialTransformation(X_train, degree)

        ##### Standardize test set with miu/std from train set
        for k in range(X_test.shape[1]):
            X_test[:, k] = (X_test[:, k] - miu_train[:, k]) / sigma_train[:, k]
        ##### make polynomial (and the first column of 1)
        X_test = PolynomialTransformation(X_test, degree)

        theta = LogisticRegressionGradientDescent(X_train, y_train, lamb, alpha, tol, iter_max)[0]
        acc[i, 0] = accuracy(X_train, y_train, theta)
        acc[i, 1] = accuracy(X_test, y_test, theta)

    return acc

##### display 10-fold cross validation accuracy (1st col: train, 2nd col:test)
##### remember here X and y are original data
acc = KFoldCrossValidation(X, y, 10)
print("Accuracy in each folding: \n", acc)
##### plot accuracy vs fold (two curves: train and test)
plot4 = plt.figure(4)
plt.plot(acc[:, 0], "-b", label="Accuracy_train")
plt.plot(acc[:, 1], "-r", label="Accuracy_test")
plt.xlabel("Fold Used as Test Set")
plt.ylabel("Accuracy")
plt.title("Accuracy in Foldings")
plt.legend(loc="upper right")

##### plot all figures
plt.show()
