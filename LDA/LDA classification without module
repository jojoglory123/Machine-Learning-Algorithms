import numpy as np
import matplotlib.pyplot as plt

#########################################################################
#################### LDA for Classification #############################
#########################################################################
##### Plot original data
data = np.loadtxt("ex2data1.txt", delimiter=',')
X = data[:, 0:-1]
y = data[:, -1].reshape(-1, 1)
X0 = X[np.where(y==0)[0], :]
X1 = X[np.where(y==1)[0], :]
plot1 = plt.figure(1)
plt.scatter(X0[:, 0], X0[:, 1], marker = "o", color = "black", label="y=0")
plt.scatter(X1[:, 0], X1[:, 1], marker = "s", color = "blue", label="y=1")
plt.gca().set_aspect('equal', adjustable='box')
plt.xlabel("Exam 1 score")
plt.ylabel("Exam 2 score")
plt.title("Scatter plot of training data")
plt.legend(loc="upper right")


##### Since the decision boundary seems linear, we use linear fitting without polynomial of X
##### Also, we don't use regularization, i.e., lambda = 0

##### Standardize data
miu = X.mean(axis=0).reshape(1, -1)
sigma = X.std(axis=0).reshape(1, -1)
X = (X-miu)/sigma

##### Filter data by class
X0 = X[np.where(y==0)[0], :]
X1 = X[np.where(y==1)[0], :]

##### Find centroid
miu0 = X0.mean(axis=0).reshape(1, -1)
miu1 = X1.mean(axis=0).reshape(1, -1)

##### Calculate Sw and w
X0_minus_miu0 =  X0 - miu0
X1_minus_miu1 =  X1 - miu1
Sw = sum(sum(X0_minus_miu0**2)) + sum(sum(X1_minus_miu1**2))
w = (1/Sw) * (miu0 - miu1).reshape(-1, 1)
##### Normalize w first since it's U_red in PCA, has to be norm 1
w = w/np.sqrt(w.T@w)

##### Plot standardized data and projection line
plot2 = plt.figure(2)
plt.scatter(X0[:, 0], X0[:, 1], marker = "o", color = "black", label="y=0")
plt.scatter(X1[:, 0], X1[:, 1], marker = "s", color = "blue", label="y=1")
plt.gca().set_aspect('equal', adjustable='box')
plt.xlabel("Exam 1 score")
plt.ylabel("Exam 2 score")
plt.title("Standardized data and projection line")


##### Find reduced coordinate
Z0 = X0 @ w
Z1 = X1 @ w

##### Recover the data with original dimensionality
X0_rec = Z0 @ w.T
X1_rec = Z1 @ w.T

##### Plot projection line
X_combine_rec = np.r_[X0_rec, X1_rec]
lower_point = X_combine_rec[np.where(X_combine_rec[:, 0]==np.amin(X_combine_rec[:, 0])), :].reshape(1, -1)
upper_point = X_combine_rec[np.where(X_combine_rec[:, 0]==np.amax(X_combine_rec[:, 0])), :].reshape(1, -1)
xlinemark = np.linspace(lower_point[0, 0], upper_point[0, 0], 10)
slope = w[1, 0] / w[0, 0]
y = slope * xlinemark

##### Plot projected points
plt.plot(xlinemark, y, linestyle = 'dotted', color = "red", label = "Projection Line and Projected Points")
plt.scatter(X0_rec[:, 0], X0_rec[:, 1], marker = "o", color = "black",facecolors='none', label="y=0")
plt.scatter(X1_rec[:, 0], X1_rec[:, 1], marker = "s", color = "blue",facecolors='none', label="y=1")


##### Present some statistics
print("Eigenvector(s) of projection space (w): \n", w)
##### Calculate variance retaiened after projection
c0_projection_error = sum(sum((X0 - X0_rec)**2))
c0_original_variance = sum(sum(X0 **2))
print("Class 0 variance retained after projection: ", 1 - (c0_projection_error / c0_original_variance)   )
c1_projection_error = sum(sum((X1 - X1_rec)**2))
c1_original_variance = sum(sum(X1 **2))
print("Class 1 variance retained after projection: ", 1 - (c1_projection_error / c1_original_variance)   )
print("Total variance retained after projection: ", (c0_projection_error+c1_projection_error)/(c0_original_variance+c1_original_variance) )

##### Prediction
def predict(X, W, Miu0, Miu1):
    pred = np.zeros((X.shape[0], 1))
    diff = (X @ W - Miu0 @ W)**2 - (X @ W - Miu1 @ W)**2
    for i in range(X.shape[0]):
        if diff[i, 0] <= 0:
            pred[i, 0] = 0
        else:
            pred[i, 0] = 1
    return pred

##### Prediction
test = np.array([[50, 60], [80, 90]])

##### normalize it
test = (test - miu) / sigma
test_pred = predict(test, w, miu0, miu1)
color = ["black", "blue"]

print("For a new X=(50, 60), predicted class is", test_pred[0, 0], ", which is", color[int(test_pred[0, 0])], "color.")
print("For a new X=(80, 90), predicted class is", test_pred[1, 0], ", which is", color[int(test_pred[1, 0])], "color.")


#########################################################################
##### k-fold cross validation ###########################################
#########################################################################

def GenerateLables(X, k):
    labels = []
    for i in range(k):
        labels.extend([i] * (X.shape[0] // k))
    if X.shape[0] // k != 0:
        for j in range(X.shape[0] % k):
            labels.extend([j])
            labels.sort()
    labels_array = np.array(labels).reshape(-1, 1)
    return labels_array

##### Note!!! To avoid data leakage, we can't standardize the entire dataset before separating to train/test
##### We have to standardize the train data first, then use the mean/sd from train to scale test.
##### So we need to use original data and Pipeline

##### Obtain original data again
data = np.loadtxt("ex2data1.txt", delimiter=',')
X = data[:, 0:-1]
y = data[:, -1]


def KFoldCrossValidation(X, y, k):
    ##### combine X and y if they are separated already
    X_y = np.c_[X, y]
    ##### always shuffle the data before CV
    np.random.shuffle(X_y)
    ##### generate (vertical vector) labels
    labels = GenerateLables(X_y, k)
    ##### attach labels to data
    X_y_shuffled_labeled = np.c_[labels, X_y]
    ##### create a matrix to store accuracy (row: fold1, ... foldk. column: train MSE, test MSE)
    acc = np.zeros((k, 2))
    for i in range(k):
        ##### select data with label = i as test set
        test = X_y_shuffled_labeled[X_y_shuffled_labeled[:, 0] == i, :]
        ##### select data with label = i as train set
        train = X_y_shuffled_labeled[X_y_shuffled_labeled[:, 0] != i, :]
        X_test = test[:, 1:-1]
        y_test = test[:, -1].reshape(-1, 1)
        X_train = train[:, 1:-1]
        y_train = train[:, -1].reshape(-1, 1)

        ##### Standardize train set
        miu_train = X_train.mean(axis=0).reshape(1, -1)
        sigma_train = X_train.std(axis=0).reshape(1, -1)
        X_train = (X_train - miu_train) / sigma_train

        ##### Filter data by class
        X0_train = X_train[np.where(y_train == 0)[0], :]
        X1_train = X_train[np.where(y_train == 1)[0], :]

        ##### Find centroid
        miu0 = X0_train.mean(axis=0).reshape(1, -1)
        miu1 = X1_train.mean(axis=0).reshape(1, -1)

        ##### Calculate Sw and w
        X0_train_minus_miu0 = X0_train - miu0
        X1_train_minus_miu1 = X1_train - miu1
        Sw = sum(sum(X0_train_minus_miu0 ** 2)) + sum(sum(X1_train_minus_miu1 ** 2))
        w = (1 / Sw) * (miu0 - miu1).reshape(-1, 1)
        ##### Normalize w first since it's U_red in PCA, has to be norm 1
        w = w / np.sqrt(w.T @ w)

        ##### Standardize test set with miu/std from train set
        X_test = (X_test - miu_train) / sigma_train

        ##### Prediction
        pred_train = predict(X_train, w, miu0, miu1)
        pred_test = predict(X_test, w, miu0, miu1)

        ##### Store accuracy
        acc[i, 0] = 1 - (pred_train - y_train).T @ (pred_train - y_train) / X_train.shape[0]
        acc[i, 1] = 1 - (pred_test - y_test).T @ (pred_test - y_test) / X_test.shape[0]

    return acc

##### display 10-fold cross validation accuracy (1st col: train, 2nd col:test)
##### remember here X and y are original data
acc = KFoldCrossValidation(X, y, 10)
print("Accuracy in each folding: \n", acc)
##### plot accuracy vs fold (two curves: train and test)
plot3 = plt.figure(3)
plt.plot(acc[:, 0], "-b", label="Accuracy_train")
plt.plot(acc[:, 1], "-r", label="Accuracy_test")
plt.xlabel("Fold Used as Test Set")
plt.ylabel("Accuracy")
plt.title("Accuracy in Foldings")
plt.legend(loc="upper right")

##### plot all figures
plt.show()
